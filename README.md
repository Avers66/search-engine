
Поисковый движок, осуществляющий поиск по заданным интернет-сайтам.

![IndexingPage](https://user-images.githubusercontent.com/122222024/211211135-960bca9b-03ac-4314-ad99-938928d5e19e.png)

Получает на выходе список найденных страниц в соответствии с заданным запросом, с учетом морфологии русского языка и релевантностью найденной информации.

![SearchPage](https://user-images.githubusercontent.com/122222024/211304586-e95688f0-702b-449c-8837-8aeeffa2bd8a.png)

Представляет из себя клиент-серверное WEB-приложение, управление которым осуществляется через обычный интернет-браузер.
Построено на основе фреймвока SPRINGFRAMEWORK.BOOT (https://spring.io/projects/spring-boot), с использованием библиотеки SPRING-BOOT-STARTER-WEB, реализующей REST-контроллеры (классы APICONTROLLER, DEFAULTCONTROLLER), осуществляющий взаимодействие между frontend и backend частями приложения, с помощью встроенного Web-сервера Apache TomCat. И библиотеки SPRING-BOOT-STARTER-DATA-JPA, включающей механизм объектно-реляционного отображения ORM HIBERNATE, дополнительный слой абстракций Jakarta Persistent API или JPA, позволяющий отображать записи в таблицах БД в экземпляры объектов Java и обратно, а также включающий ряд удобных методов работы с БД в стиле Java, а не в виде запросов SQL. Подключение зависимостей можно увидеть в файле pom.xml данного проекта с настройка длф фреймворка MAVEN (https://maven.apache.org).

Обход сайтов реализован в классе CRAWLER (интернет-паук) в многопоточном режиме c полной или частичной загрузкой всех имеющихся процессоров/ядер/сред с использованием фреймворка FORK/JOIN, с разбиением работы на множество мелких подзадач от сотен до десятков тысяч и равномерное их распределение по очередям к средам исполнения. 

Для парсинга ссылок, найденных на HTML-страницах используется библиотека JSOUP (https://jsoup.org). Найденные гиперссылки рекурсивно передаются для последующего парсинга вновь создаваемым для этого экземлярам классов, унаследованным от RecursiveAction с помощью метода fork. Содержимое, после удаления всей не текстовой информации, кроме заголовка страницs Title, адреса страниц, коды ответа HTTP записываются в таблицу PAGE базы данных. 

В качестве базы данных можно использовать любую реляционную СУБД. В данном проекте подключена СУБД MySQL.  Для ее работы необходимо установить соответствующий сервер СУБД и средство управления им, например WorkBench для MySQL и создать пустую схему БД с названием search_engine.

![YML1![WorkBench](https://user-images.githubusercontent.com/122222024/211324980-f9eb4918-3d29-4b72-811b-2705bb246778.png)

Настроить соответствующий диалект БД в поле DIALECT. Путь подключения, имя и пароль пользователя с правами root в полях URL, USER, PASSWORD соответственно. Также при первом запуске программы для автоматического создания таблиц в БД необходимо установить параметр     DDL-AUTO: CREATE-DROP, а при обычной работе программы параметр должен быть установлен в UPDATE. 

![YML1](https://user-images.githubusercontent.com/122222024/211325389-515dd0d3-d428-45c0-bc0d-d4dce80cdfbf.png)

Также необходимо добавить зависимость для подключения библиотеки коннектора подключения к соответствующей БД. Для фреймворка MAVEN в файл pom.xml необходимо добавить следующие строки.

![YML2](https://user-images.githubusercontent.com/122222024/211324548-ef09316c-2c1d-4918-9a4f-77805a6541cf.png)

Перед сохранением в БД из содержимого обнаруженных HTML-страниц выделяются все слова. Затем происходит исключение служебных частей речи и преобразование всех оставшихся слов в нормальную форму. Например, существительные преобразуются в именительный падеж, единственное число, мужской род. Данные преобразования производятся с помощью библиотеки морфологической обработки текста APACHE LUCENE MORPHOLOGY (https://mvnrepository.com/artifact/org.apache.lucene.morphology). Русскоязычная версия данной библиотеки собрана , скомпилирована образовательной платформой (https://skillbox.ru) и находится в их репозитории. Подключение  библиотеки можно проследить в файле pom.xml проекта. Такие преобразованные слова называются леммамами , а процесс преобразования лемматизацией. Далее подсчитывается количество вхождений каждого слова на данной странице и данные разносятся по таблицам LEMMA и INDEX, формируя индекс поиска для каждого слова и его связи со страницами (таблица PAGE), на которых оно присутствует. Количество вхождений на данной странице записывается в поле RANK таблицы INDEX, а количество страниц, на которых присутствует лемма по мере обхода страниц аккумулируются  в поле FREQUENCY таблицы ЛЕММА.




